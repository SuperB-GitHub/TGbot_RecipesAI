import pandas as pd
import ast
from sentence_transformers import SentenceTransformer
from sentence_transformers import util
import torch
import pickle


# --- 1. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ ---
def preprocess_recipe(row):
    name = row['name'] if isinstance(row['name'], str) else ''
    ingredients = ' '.join(ast.literal_eval(row['nor_ingridients'])) if isinstance(row['nor_ingridients'], str) else ''
    instructions = row['instructions'].lower() if isinstance(row['instructions'], str) else ''

    enhanced_text = (
        (name + ' ') * 2 +
        (ingredients + ' ') * 3 +
        (instructions + ' ') * 2
    ).strip().lower()

    return enhanced_text

# --- 2. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ ---
print("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
df = pd.read_csv("List_of_Recipes.csv")

# --- 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ ---
print("üßπ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ—Ü–µ–ø—Ç–æ–≤...")
df['clean_text'] = df.apply(preprocess_recipe, axis=1)

# --- 4. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ ---
print("üß† –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')

# # --- 5. –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ ---
# print("üß¨ –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ—Ü–µ–ø—Ç–æ–≤...")
# recipe_texts = df['clean_text'].tolist()
# recipe_embeddings = model.encode(recipe_texts, show_progress_bar=True)
# with open("recipe_embeddings.pkl", "wb") as f:
#     pickle.dump(recipe_embeddings, f)


# --- 5. –ó–∞–≥—Ä—É–∑–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ ---
print("üß¨ –ó–∞–≥—Ä—É–∑–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
with open("recipe_embeddings.pkl", "rb") as f:
    recipe_embeddings = pickle.load(f)


# --- 6. –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ ---
def find_recipes(query, top_n=5):
    filtered_df = filter_by_keywords(df, query)
    filtered_indices = filtered_df.index.tolist()
    filtered_embeddings = recipe_embeddings[filtered_indices]
    
    query_embedding = model.encode([query.lower()])
    cos_scores = util.cos_sim(query_embedding, filtered_embeddings)[0]
    
    top_k = min(top_n * 3, len(filtered_indices))
    top_indices_in_subset = torch.topk(cos_scores, k=top_k).indices.tolist()
    result_indices = [filtered_indices[i] for i in top_indices_in_subset]

    results = []
    for idx in result_indices:
        results.append({
            'name': df.iloc[idx]['name'],
            'ingredients': df.iloc[idx]['pure_ingridients'],
            'instructions': df.iloc[idx]['instructions'],
            'score': cos_scores[result_indices.index(idx)].item()
        })
        if len(results) >= top_n:
            break

    return results

# --- 7. –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ ---
def filter_by_keywords(df, query, column='clean_text'):
    stopwords = {'–≤', '–Ω–∞', '—Å', '–ø–æ', '–¥–ª—è', '–∏–∑', '–æ—Ç', '–¥–æ', '–∏', '–∏–ª–∏', '–Ω–µ'}
    query_words = [word.strip() for word in query.lower().split(',') if word.strip() not in stopwords]

    filtered = df[df[column].apply(lambda x: all(word in x for word in query_words))]
    
    if filtered.empty:
        filtered = df[df[column].apply(lambda x: any(word in x for word in query_words))]

    return filtered if not filtered.empty else df

# --- 8. –û—Å–Ω–æ–≤–Ω–æ–π –±–ª–æ–∫ ---
if __name__ == "__main__":
    user_query = input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å: ")

    print(f"\nüîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{user_query}'")
    results = find_recipes(user_query, top_n=5)

    if not results:
        print("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É.")
    else:
        for res in results:
            print("\n------------------------------")
            print(f"üçΩÔ∏è {res['name']} | Score: {res['score']:.4f}")
            print(f"üßÇ –ò–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã: {res['ingredients']}")
            print(f"üßÇ –ö–∞–∫ –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—å:\n {res['instructions']}")