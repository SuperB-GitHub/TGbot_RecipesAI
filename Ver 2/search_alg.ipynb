{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d9d54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from sentence_transformers import util\n",
    "from sentence_transformers import SentenceTransformer, models, losses\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers.readers import InputExample\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "\n",
    "# --- 1. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ ---\n",
    "def preprocess_recipe(row):\n",
    "    name = row['name'] if isinstance(row['name'], str) else ''\n",
    "    ingredients = ' '.join(ast.literal_eval(row['nor_ingridients'])) if isinstance(row['nor_ingridients'], str) else ''\n",
    "    instructions = row['instructions'].lower() if isinstance(row['instructions'], str) else ''\n",
    "\n",
    "    enhanced_text = (\n",
    "        (name + ' ') * 2 +\n",
    "        (ingredients + ' ') * 3 +\n",
    "        (instructions + ' ') * 2\n",
    "    ).strip().lower()\n",
    "\n",
    "    return enhanced_text\n",
    "\n",
    "# --- 2. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ ---\n",
    "print(\"üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...\")\n",
    "df = pd.read_csv(\"List_of_Recipes.csv\")\n",
    "\n",
    "# --- 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ ---\n",
    "print(\"üßπ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ—Ü–µ–ø—Ç–æ–≤...\")\n",
    "df['clean_text'] = df.apply(preprocess_recipe, axis=1)\n",
    "\n",
    "# --- 4. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ ---\n",
    "print(\"üß† –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...\")\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# --- 5. –î–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ ---\n",
    "def training(model):\n",
    "    train_examples = [\n",
    "    InputExample(texts=['–°–ø–∞–≥–µ—Ç—Ç–∏ —Å –∫—Ä–µ–≤–µ—Ç–∫–∞–º–∏', '–ö—Ä–µ–≤–µ—Ç–∫–∏ –≤ —Ç–æ–º–∞—Ç–Ω–æ-—Å–ª–∏–≤–æ—á–Ω–æ–º —Å–æ—É—Å–µ'], label=4.7),\n",
    "    InputExample(texts=['–ü–∏—Ü—Ü–∞ –º–∞—Ä–≥–∞—Ä–∏—Ç–∞', '–ü–∏—Ü—Ü–∞ —Å —Å—ã—Ä–æ–º –∏ –±–∞–∑–∏–ª–∏–∫–æ–º'], label=4.9),\n",
    "    InputExample(texts=['–°—É–ø —Å —Ñ–∞—Å–æ–ª—å—é', '–ö–∞—à–∞ –∏–∑ –≥—Ä–µ—á–∫–∏'], label=1.0),\n",
    "]\n",
    "    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "    train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "    # –û–±—É—á–µ–Ω–∏–µ\n",
    "    model.fit(\n",
    "        train_objectives=[(train_dataloader, train_loss)],\n",
    "        epochs=3,\n",
    "        warmup_steps=100,\n",
    "        output_path='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "    )\n",
    "    \n",
    "\n",
    "# # --- 5. –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ ---\n",
    "# print(\"üß¨ –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ—Ü–µ–ø—Ç–æ–≤...\")\n",
    "# recipe_texts = df['clean_text'].tolist()\n",
    "# recipe_embeddings = model.encode(recipe_texts, show_progress_bar=True)\n",
    "# with open(\"recipe_embeddings.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(recipe_embeddings, f)\n",
    "\n",
    "\n",
    "# --- 5. –ó–∞–≥—Ä—É–∑–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ ---\n",
    "print(\"üß¨ –ó–∞–≥—Ä—É–∑–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...\")\n",
    "with open(\"recipe_embeddings.pkl\", \"rb\") as f:\n",
    "    recipe_embeddings = pickle.load(f)\n",
    "\n",
    "\n",
    "# --- 6. –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ ---\n",
    "def find_recipes(query, top_n=5):\n",
    "    filtered_df = filter_by_keywords(df, query)\n",
    "    filtered_indices = filtered_df.index.tolist()\n",
    "    filtered_embeddings = recipe_embeddings[filtered_indices]\n",
    "    \n",
    "    query_embedding = model.encode([query.lower()])\n",
    "    cos_scores = util.cos_sim(query_embedding, filtered_embeddings)[0]\n",
    "    \n",
    "    top_k = min(top_n * 3, len(filtered_indices))\n",
    "    top_indices_in_subset = torch.topk(cos_scores, k=top_k).indices.tolist()\n",
    "    result_indices = [filtered_indices[i] for i in top_indices_in_subset]\n",
    "\n",
    "    results = []\n",
    "    for idx in result_indices:\n",
    "        results.append({\n",
    "            'name': df.iloc[idx]['name'],\n",
    "            'ingredients': df.iloc[idx]['pure_ingridients'],\n",
    "            'instructions': df.iloc[idx]['instructions'],\n",
    "            'score': cos_scores[result_indices.index(idx)].item()\n",
    "        })\n",
    "        if len(results) >= top_n:\n",
    "            break\n",
    "\n",
    "    return results\n",
    "\n",
    "# --- 7. –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ ---\n",
    "def filter_by_keywords(df, query, column='clean_text'):\n",
    "    stopwords = {'–≤', '–Ω–∞', '—Å', '–ø–æ', '–¥–ª—è', '–∏–∑', '–æ—Ç', '–¥–æ', '–∏', '–∏–ª–∏', '–Ω–µ'}\n",
    "    query_words = [word.strip() for word in query.lower().split(',') if word.strip() not in stopwords]\n",
    "\n",
    "    filtered = df[df[column].apply(lambda x: all(word in x for word in query_words))]\n",
    "    \n",
    "    if filtered.empty:\n",
    "        filtered = df[df[column].apply(lambda x: any(word in x for word in query_words))]\n",
    "\n",
    "    return filtered if not filtered.empty else df\n",
    "\n",
    "# --- 8. –û—Å–Ω–æ–≤–Ω–æ–π –±–ª–æ–∫ ---\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = input(\"–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å: \")\n",
    "\n",
    "    print(f\"\\nüîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{user_query}'\")\n",
    "    results = find_recipes(user_query, top_n=5)\n",
    "\n",
    "    if not results:\n",
    "        print(\"–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É.\")\n",
    "    else:\n",
    "        for res in results:\n",
    "            print(\"\\n------------------------------\")\n",
    "            print(f\"üçΩÔ∏è {res['name']} | Score: {res['score']:.4f}\")\n",
    "            print(f\"üßÇ –ò–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã: {res['ingredients']}\")\n",
    "            print(f\"üßÇ –ö–∞–∫ –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—å:\\n {res['instructions']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
